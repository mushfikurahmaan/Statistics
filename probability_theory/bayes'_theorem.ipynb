{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes' Theorem\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c9/Bayes_theorem_visual_proof.svg/512px-Bayes_theorem_visual_proof.svg.png\" alt=\"description\" width=\"auto\">\n",
    "</center>\n",
    "\n",
    "### Introduction\n",
    "**Bayes' Theorem** is a powerful tool in probability theory that allows us to update our beliefs based on new evidence. Developed by the English statistician Thomas Bayes, this theorem is widely applied in fields such as medicine, finance, and data science to refine predictions and make decisions in the face of uncertainty.\n",
    "\n",
    "In simple terms, Bayes' Theorem answers the question: \"Given what I know now, how likely is something to be true?\" It balances prior knowledge with new evidence to update probabilities, making it particularly useful for dealing with uncertain or incomplete data.\n",
    "\n",
    "### The Basics of Bayes’ Theorem\n",
    "\n",
    "Mathematically, Bayes' Theorem is expressed as:\n",
    "\n",
    "$$\n",
    "P(H|E) = \\frac{P(E|H) \\cdot P(H)}{P(E)}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $  P(H|E) $  is the **posterior probability**: the updated probability of a hypothesis $  H $  being true after considering new evidence $  E $ .\n",
    "- $  P(E|H) $  is the **likelihood**: the probability of observing the evidence $  E $ , assuming the hypothesis $  H $  is true.\n",
    "- $  P(H) $  is the **prior probability**: the initial probability of the hypothesis before seeing the new evidence.\n",
    "- $  P(E) $  is the **marginal likelihood**: the total probability of observing the evidence, regardless of the hypothesis.\n",
    "\n",
    "### Key Concepts: Conditional, Joint, and Marginal Probabilities\n",
    "\n",
    "Before diving into Bayes’ Theorem, it's important to understand three foundational concepts: **conditional probability**, **joint probability**, and **marginal probability**.\n",
    "\n",
    "#### 1. **Conditional Probability**\n",
    "Conditional probability represents the probability of an event occurring, given that another event has already occurred. For example, let's consider the probability of a person having long hair given that they are a woman:\n",
    "\n",
    "$$\n",
    "P(\\text{Long Hair | Woman}) = \\frac{P(\\text{Woman and Long Hair})}{P(\\text{Woman})}\n",
    "$$\n",
    "\n",
    "If 60% of women have long hair, the conditional probability $  P(\\text{Long Hair | Woman}) $  would be 0.6. This is different from $  P(\\text{Woman | Long Hair}) $ , which represents the probability that a person is a woman, given that they have long hair.\n",
    "\n",
    "#### 2. **Joint Probability**\n",
    "Joint probability refers to the probability of two events happening together. For example, the probability of a person being a woman and having long hair is:\n",
    "\n",
    "$$\n",
    "P(\\text{Woman and Long Hair}) = P(\\text{Woman}) \\times P(\\text{Long Hair | Woman})\n",
    "$$\n",
    "\n",
    "If 50% of people are women and 60% of women have long hair, the joint probability would be:\n",
    "\n",
    "$$\n",
    "P(\\text{Woman and Long Hair}) = 0.5 \\times 0.6 = 0.3\n",
    "$$\n",
    "\n",
    "This means 30% of the population are women with long hair.\n",
    "\n",
    "#### 3. **Marginal Probability**\n",
    "Marginal probability refers to the overall probability of an event occurring, regardless of other conditions. In our example, the marginal probability of having long hair, considering both men and women, would be:\n",
    "\n",
    "$$\n",
    "P(\\text{Long Hair}) = P(\\text{Woman and Long Hair}) + P(\\text{Man and Long Hair})\n",
    "$$\n",
    "\n",
    "If 30% of people are women with long hair and 10% are men with long hair, then:\n",
    "\n",
    "$$\n",
    "P(\\text{Long Hair}) = 0.3 + 0.1 = 0.4\n",
    "$$\n",
    "\n",
    "This means 40% of the population has long hair.\n",
    "\n",
    "### Deriving Bayes’ Theorem\n",
    "Now, let's connect these ideas to derive Bayes' Theorem. Suppose we want to calculate the probability that a person is a man, given that they have long hair:\n",
    "\n",
    "$$\n",
    "P(\\text{Man | Long Hair})\n",
    "$$\n",
    "\n",
    "Using the concept of joint probability:\n",
    "\n",
    "$$\n",
    "P(\\text{Man and Long Hair}) = P(\\text{Man}) \\times P(\\text{Long Hair | Man})\n",
    "$$\n",
    "\n",
    "This is equivalent to:\n",
    "\n",
    "$$\n",
    "P(\\text{Man and Long Hair}) = P(\\text{Long Hair}) \\times P(\\text{Man | Long Hair})\n",
    "$$\n",
    "\n",
    "Setting these equal:\n",
    "\n",
    "$$\n",
    "P(\\text{Man}) \\times P(\\text{Long Hair | Man}) = P(\\text{Long Hair}) \\times P(\\text{Man | Long Hair})\n",
    "$$\n",
    "\n",
    "Solving for $  P(\\text{Man | Long Hair}) $ :\n",
    "\n",
    "$$\n",
    "P(\\text{Man | Long Hair}) = \\frac{P(\\text{Man}) \\times P(\\text{Long Hair | Man})}{P(\\text{Long Hair})}\n",
    "$$\n",
    "\n",
    "### Example of Bayes’ Theorem\n",
    "Let’s use an example:\n",
    "\n",
    "- $  P(\\text{Man}) = 0.5 $  (50% of the population are men).\n",
    "- $  P(\\text{Long Hair | Man}) = 0.1 $  (10% of men have long hair).\n",
    "- $  P(\\text{Long Hair}) = 0.4 $  (40% of the population has long hair).\n",
    "\n",
    "Using Bayes' Theorem:\n",
    "\n",
    "$$\n",
    "P(\\text{Man | Long Hair}) = \\frac{0.5 \\times 0.1}{0.4} = \\frac{0.05}{0.4} = 0.125\n",
    "$$\n",
    "\n",
    "So, given that a person has long hair, there is a **12.5% chance** they are a man.\n",
    "\n",
    "### Real-World Applications\n",
    "\n",
    "#### 1. **Medical Diagnosis**\n",
    "In healthcare, Bayes' Theorem is used to interpret test results by considering both the accuracy of the test and the prevalence of the disease. For example, if a disease affects 1% of the population and a test has a 90% detection rate, Bayes’ Theorem helps estimate the true likelihood of the disease given a positive result.\n",
    "\n",
    "#### 2. **Spam Filtering**\n",
    "Email services apply Bayes' Theorem to detect spam. Given that certain keywords are more likely to appear in spam emails, the algorithm calculates the probability that a message is spam based on its content.\n",
    "\n",
    "#### 3. **Risk Assessment in Finance**\n",
    "Bayes' Theorem helps financial institutions assess the likelihood of loan defaults by updating predictions based on new financial data like credit scores or payment history.\n",
    "\n",
    "### Conclusion\n",
    "By combining **conditional**, **joint**, and **marginal probabilities**, Bayes' Theorem becomes a powerful tool for updating our beliefs in light of new evidence. Whether in data science, medicine, or everyday decisions, it helps us make more informed choices in uncertain situations.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
